"""
Training script for MapGlow model using VBD's data pipeline.
Based on VBD's train.py structure - fully compatible with VBD infrastructure.
"""
import sys
import os
from pathlib import Path

# Add VBD to path
vbd_root = Path(__file__).parent.parent.absolute()
if str(vbd_root) not in sys.path:
    sys.path.insert(0, str(vbd_root))

import torch
import yaml
import datetime
import argparse

os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"

# Set TF and JAX to CPU only (with error handling for environment issues)
try:
    import tensorflow as tf
    tf.config.set_visible_devices([], "GPU")
except Exception as e:
    print(f"Warning: Could not configure TensorFlow: {e}")

try:
    import jax
    jax.config.update("jax_platform_name", "cpu")
except Exception as e:
    print(f"Warning: Could not configure JAX: {e}")

from vbd.data.dataset import WaymaxDataset
from vbd.model.MapGlowWrapper import MapGlowWrapper
from torch.utils.data import DataLoader

import lightning.pytorch as pl
from lightning.pytorch.callbacks import ModelCheckpoint, LearningRateMonitor
from lightning.pytorch.loggers import WandbLogger, CSVLogger
from lightning.pytorch.strategies import DDPStrategy

from matplotlib import pyplot as plt


def load_config(file_path):
    """Load configuration from YAML file."""
    with open(file_path, "r") as file:
        data = yaml.safe_load(file)
    return data


def train(cfg):
    """Main training function - same structure as VBD's train()."""
    print("=" * 60)
    print("Starting MapGlow Training with VBD Pipeline")
    print("=" * 60)
    
    pl.seed_everything(cfg["seed"])
    torch.set_float32_matmul_precision("high")
    
    # Create datasets (same as VBD)
    print("\nLoading datasets...")
    train_dataset = WaymaxDataset(
        data_dir=cfg["train_data_path"],
        anchor_path=cfg["anchor_path"],
    )
    
    val_dataset = WaymaxDataset(
        data_dir=cfg["val_data_path"],
        anchor_path=cfg["anchor_path"],
    )
    
    print(f"  Train samples: {len(train_dataset)}")
    print(f"  Val samples: {len(val_dataset)}")
    
    # Create dataloaders (same as VBD)
    train_loader = DataLoader(
        train_dataset,
        batch_size=cfg["batch_size"],
        pin_memory=True,
        num_workers=cfg["num_workers"],
        shuffle=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=cfg["batch_size"],
        pin_memory=True,
        num_workers=cfg["num_workers"],
        shuffle=False
    )
    
    # Setup output directory (same as VBD)
    output_root = cfg.get("log_dir", "output")
    timestamp = datetime.datetime.now().strftime("%Y%m%d%H%M%S")
    model_name = f"{cfg['model_name']}_{timestamp}"
    output_path = f"{output_root}/{model_name}"
    print(f"\nOutput directory: {output_path}")
    
    os.makedirs(output_path, exist_ok=True)
    
    # Save config (same as VBD)
    with open(f"{output_path}/config.yaml", "w") as file:
        yaml.dump(cfg, file)
    
    # Build model
    num_gpus = torch.cuda.device_count()
    print(f"\nTotal GPUs: {num_gpus}")
    
    model = MapGlowWrapper(cfg=cfg)
    print(f"Model parameters: {sum(p.numel() for p in model.parameters()):,}")
    
    # Load checkpoint if specified (same logic as VBD)
    ckpt_path = cfg.get("ckpt_path", None)
    if ckpt_path is not None and os.path.exists(ckpt_path):
        print(f"\nLoading weights from: {ckpt_path}")
        state_dict = torch.load(ckpt_path, map_location=torch.device("cpu"))
        if "state_dict" in state_dict:
            state_dict = state_dict["state_dict"]
        model.load_state_dict(state_dict, strict=False)
    
    # Load pre-trained encoder if specified (same as VBD)
    if not cfg.get('train_encoder', True):
        encoder_path = cfg.get("encoder_ckpt", None)
        if encoder_path is not None and os.path.exists(encoder_path):
            print(f"\nLoading encoder weights from: {encoder_path}")
            model.load_encoder_weights(encoder_path)
        else:
            cfg["train_encoder"] = True
            print("Warning: Encoder path not provided, training encoder from scratch")
    
    # Setup logger (same as VBD)
    use_wandb = cfg.get("use_wandb", False)
    if use_wandb:
        logger = WandbLogger(
            name=model_name,
            project=cfg.get("project", "MapGlow"),
            entity=cfg.get("username"),
            log_model=False,
            dir=output_path,
        )
    else:
        logger = CSVLogger(output_path, name="MapGlow", version=1, flush_logs_every_n_steps=100)
    
    # Setup trainer (same as VBD)
    trainer = pl.Trainer(
        num_nodes=cfg.get("num_nodes", 1),
        max_epochs=cfg["epochs"],
        devices=cfg.get("num_gpus", -1),
        accelerator="gpu" if torch.cuda.is_available() else "cpu",
        strategy=DDPStrategy() if num_gpus > 1 else "auto",
        enable_progress_bar=True,
        logger=logger,
        enable_model_summary=True,
        detect_anomaly=False,
        gradient_clip_val=cfg.get("gradient_clip_val", 1.0),
        gradient_clip_algorithm="norm",
        num_sanity_val_steps=0,
        precision=cfg.get("precision", "bf16-mixed"),
        log_every_n_steps=cfg.get("log_every_n_steps", 100),
        callbacks=[
            ModelCheckpoint(
                dirpath=output_path,
                save_top_k=cfg.get("save_top_k", 20),
                save_weights_only=False,
                monitor="val/loss",
                mode="min",
                filename="epoch={epoch:02d}",
                auto_insert_metric_name=False,
                every_n_epochs=1,
                save_on_train_epoch_end=False,
            ),
            LearningRateMonitor(logging_interval="step")
        ]
    )
    
    print("\nStarting training...")
    print("=" * 60)
    
    trainer.fit(
        model,
        train_loader,
        val_loader,
        ckpt_path=cfg.get("init_from")
    )
    
    print("\nTraining completed!")


def build_parser():
    """Build argument parser - same structure as VBD."""
    parser = argparse.ArgumentParser(description="MapGlow Training with VBD Pipeline")
    parser.add_argument("-cfg", "--cfg", type=str, default="config/MapGlow.yaml",
                        help="Path to config file")
    
    # Data paths
    parser.add_argument("--train_data_path", type=str, default=None,
                        help="Training data directory")
    parser.add_argument("--val_data_path", type=str, default=None,
                        help="Validation data directory")
    
    # Model name and logging
    parser.add_argument("-name", "--model_name", type=str, default=None,
                        help="Model name for logging")
    parser.add_argument("-log", "--log_dir", type=str, default=None,
                        help="Log directory")
    
    # Training parameters
    parser.add_argument("-bs", "--batch_size", type=int, default=None,
                        help="Batch size")
    parser.add_argument("-lr", "--lr", type=float, default=None,
                        help="Learning rate")
    parser.add_argument("-e", "--epochs", type=int, default=None,
                        help="Number of epochs")
    
    # MapGlow specific parameters
    parser.add_argument("--n_flow", type=int, default=None,
                        help="Number of flows per block")
    parser.add_argument("--n_block", type=int, default=None,
                        help="Number of blocks")
    parser.add_argument("--condition_dim", type=int, default=None,
                        help="Condition dimension")
    parser.add_argument("--affine", action="store_true",
                        help="Use affine coupling")
    parser.add_argument("--temperature", type=float, default=None,
                        help="Sampling temperature")
    
    # Encoder settings (same as VBD)
    parser.add_argument("-eV", "--encoder_version", type=str, default=None,
                        help="Encoder version (v1 or v2)")
    parser.add_argument("-encoder", "--encoder_ckpt", type=str, default=None,
                        help="Pre-trained encoder checkpoint")
    parser.add_argument("--train_encoder", type=bool, default=None,
                        help="Whether to train encoder")
    
    # Hardware (same as VBD)
    parser.add_argument("-nN", "--num_nodes", type=int, default=1,
                        help="Number of nodes")
    parser.add_argument("-nG", "--num_gpus", type=int, default=-1,
                        help="Number of GPUs (-1 for all)")
    
    # Resume training (same as VBD)
    parser.add_argument("-init", "--init_from", type=str, default=None,
                        help="Resume from checkpoint")
    parser.add_argument("-ckpt", "--ckpt_path", type=str, default=None,
                        help="Load model weights from checkpoint")
    
    return parser


def load_cfg(args):
    """Load config and override with command line arguments."""
    cfg = load_config(args.cfg)
    
    # Override config from args
    for key, value in vars(args).items():
        if key == "cfg":
            continue
        elif value is not None:
            cfg[key] = value
    
    return cfg


if __name__ == "__main__":
    parser = build_parser()
    args = parser.parse_args()
    cfg = load_cfg(args)
    
    train(cfg)
